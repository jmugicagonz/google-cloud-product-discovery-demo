{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a565ca9b",
   "metadata": {},
   "source": [
    "# From raw catalog in JSON to catalog in JSONL suitable for BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c97cc67",
   "metadata": {},
   "source": [
    "## Preliminary steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e929dda8",
   "metadata": {},
   "source": [
    "### Install the libraries used in this tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea8e9fa",
   "metadata": {},
   "source": [
    "Library to authenticate with Google Cloud products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7d51dcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-auth in /home/jupyter/.local/lib/python3.7/site-packages (2.15.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth) (1.15.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth) (4.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth) (4.7.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade google-auth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708bf9ed",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c45f4c",
   "metadata": {},
   "source": [
    "Google Cloud client library for Cloud Storage (GCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2a733e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6670cdc7",
   "metadata": {},
   "source": [
    "### Define global project variables and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "05157754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name for the new bucket. Change the bucker name to an unique bucket name.\n",
    "bucket_name = \"pod-fr-retail-retailsearch-asset\"\n",
    "# The name for the file to import from GCS\n",
    "source_blob_name = \"products.json\"\n",
    "# The name for the JSONL file to write back in GCS\n",
    "destination_blob_name = \"products_bq.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffede2be",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b12fbf",
   "metadata": {},
   "source": [
    "Function to read content of a blob in GCS and parse as a JSON (https://cloud.google.com/storage/docs/downloading-objects#client-libraries-download-object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8bcd4d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "    \"\"\"Downloads a blob from the bucket.\"\"\"\n",
    "    # The ID of your GCS bucket\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "\n",
    "    # The ID of your GCS object\n",
    "    # source_blob_name = \"storage-object-name\"\n",
    "\n",
    "    # The path to which the file should be downloaded\n",
    "    # destination_file_name = \"local/path/to/file\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    # Construct a client side representation of a blob.\n",
    "    # Note `Bucket.blob` differs from `Bucket.get_blob` as it doesn't retrieve\n",
    "    # any content from Google Cloud Storage. As we don't need additional data,\n",
    "    # using `Bucket.blob` is preferred here.\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    blob.download_to_filename(destination_file_name)\n",
    "\n",
    "    print(\n",
    "        \"Downloaded storage object {} from bucket {} to local file {}.\".format(\n",
    "            source_blob_name, bucket_name, destination_file_name\n",
    "        )\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3164f2d6",
   "metadata": {},
   "source": [
    "Function to write content into a blob and upload it to GCS (https://cloud.google.com/storage/docs/uploading-objects#storage-upload-object-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bbca2ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # The ID of your GCS bucket\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # The path to your file to upload\n",
    "    # source_file_name = \"local/path/to/file\"\n",
    "    # The ID of your GCS object\n",
    "    # destination_blob_name = \"storage-object-name\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\n",
    "        f\"File {source_file_name} uploaded to {destination_blob_name}.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63ab106",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfa259e",
   "metadata": {},
   "source": [
    "Download blob from GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4bfa47c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded storage object products.json from bucket pod-fr-retail-retailsearch-asset to local file products.json.\n"
     ]
    }
   ],
   "source": [
    "products_blob = download_blob(bucket_name, source_blob_name, source_blob_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51c15c4",
   "metadata": {},
   "source": [
    "Open file and parse as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "01e6e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = json.load(open(source_blob_name, 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a84b6",
   "metadata": {},
   "source": [
    "Transform categories into Retail API format (see https://cloud.google.com/retail/docs/reference/rest/v2/projects.locations.catalogs.branches.products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2b9839c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for product in products:\n",
    "    product[\"category\"] = (' > '.join(category[\"name\"] for category in product[\"category\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aef0d7",
   "metadata": {},
   "source": [
    "Transform JSON into JSONL format (see https://stackoverflow.com/questions/51300674/converting-json-into-newline-delimited-json-in-python/51301075#51301075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "614f432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = ('\\n'.join([json.dumps(record) for record in products]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f0c653",
   "metadata": {},
   "source": [
    "Write contents into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a52fc5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35089846"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = open(destination_blob_name, 'w')\n",
    "output.write(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c694a",
   "metadata": {},
   "source": [
    "Upload file to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "681b3bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File products_bq.json uploaded to products_bq.json.\n"
     ]
    }
   ],
   "source": [
    "upload_blob(bucket_name, destination_blob_name, destination_blob_name)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
